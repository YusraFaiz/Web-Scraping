# Web-Scraping
Web scraping is the process of collecting and parsing raw data from the Web, and the Python community has come up with some pretty powerful web scraping tools.
Collecting data from websites using an automated process is known as web scraping. Some websites explicitly forbid users from scraping their data with automated tools like the ones you’ll create in this tutorial. Websites do this for two possible reasons:

The site has a good reason to protect its data. For instance, Google Maps doesn’t let you request too many results too quickly.
Making many repeated requests to a website’s server may use up bandwidth, slowing down the website for other users and potentially overloading the server such that the website stops responding entirely.

This is a powerful project because you’ll be able to apply the same process and the same tools to any static website out there on the World Wide Web.

#Beautifulsoup library
Beautiful Soup is a Python library for parsing structured data. It allows you to interact with HTML in a similar way to how you would interact with a web page using developer tools. Beautiful Soup exposes a couple of intuitive functions you can use to explore the HTML you received. 
$ pip3 install beautifulsoup4
Then, import the library and create a Beautiful Soup object:


**TO RUN THIS PROJECT**
1) Make a new folder --> "scraper" and paste it on desktop.
2) open cmd 
3) change the directory to  cd Desktop/scraper
4) create virtual env by typing--> virtualenv env
5) cd env
6) cd scripts
7) activate
8) cd..
9) cd..
10) cd mysite
11) python manage.py runserver
12) copy the localhost server address and paste it on browser
13) you are done!!!!!
